<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F02%2F12%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
  <entry>
    <title><![CDATA[人脸检测和人脸对齐C++工程]]></title>
    <url>%2F2018%2F08%2F21%2Fface_detector%2F</url>
    <content type="text"><![CDATA[人脸检测和人脸对齐C++工程1、前言该工程分为人脸检测，人脸对齐和特征点平滑处理三个部分。 人脸检测 采用FaceBoxes作为解决方案，参考论文《FaceBoxes: A CPU Real-time Face Detector with High Accuracy》。并且在该论文提出的网络结构基础上，进行了网络压缩，使其达到更快的速度，详情见model文件夹中的README.md 人脸对齐 采用dlib库中的ERT作为解决方案，参考论文《One Millisecond Face Alignment with an Ensemble of Regression Trees》 特征点平滑处理 由于使用ERT进行视频帧的特征点检测时，特征点会出现明显的抖动，所以采用卡尔曼滤波进行平滑处理，参考论文《Automatic facial landmark tracking in video sequences using kalman filter assisted active shape models》 2、流程说明总体流程 调整人脸检测框流程 在上述流程中，由于检测算法得到的人脸框普遍无法将所有的68个人脸特征点包含进来，因此引入调整人脸检测框位置这一步，具体步骤如下图所示： 卡尔曼滤波处理流程 卡尔曼滤波分别针对68个特征点中嘴部、眼睛、面部轮廓和其他区域4个部分进行滤波，这四个部分的原理相同，只是参数的设置不同。以其中一个为例，如下图所示： 3、依赖环境 FaceBoxes caffe环境 dlib 19.15 Opencv 3.1.0 CentOS Linux release 7.2 4、API类说明 1FacenetCaffe 该类用于封装人脸检测的功能函数 1FaceLandmarkDetector 该类用于封装人脸特征点检测的功能函数 函数说明 class FacenetCaffe 1int initModel(const string &amp; model_path, const string &amp; weights_path, const string &amp; mean_value) 参数 model_path —— 网络模型路径 weights_path —— 网络权重路径 mean_value —— 图像均值 返回值 int类型，用于返回错误码，可根据实际情况进行修改 作用 初始化人脸检测模型 1vector&lt;vector&lt;float&gt;&gt; detectFace(const cv::Mat &amp; img) 参数 img —— 待检测图片 返回值 检测到人脸的坐标值 作用 检测img中人脸坐标值 class FaceLandmarkDetector 1void init(const string model_path) 参数 model_path —— ERT模型路径 返回值 空 作用 初始化ERT模型和卡尔曼滤波参数 1int GetFaceBox(FacenetCaffe fc_box, cv::Mat image, std::vector&lt;std::vector&lt;int&gt;&gt; &amp; face_box, float confidence_threshold, double &amp; time_detec) 参数 fc_box —— FacenetCaffe类的对象 image —— 待检测人脸框的图像 face_box —— 检测出来的人脸框 confidence_threshold —— 置信度阈值 time_detec —— 检测时间 返回值 int类型，用于返回错误码，可根据实际情况进行修改 作用 利用类FacenetCaffe中的detectFace方法检测图片的人脸框位置，并计算检测时间 1int AdjustFaceBox(cv::Mat image, std::vector&lt;std::vector&lt;int&gt;&gt; &amp; face_box) 参数 image —— 待检测人脸框的图像 face_box —— 由GetFaceBox检测出来的人脸框 返回值 int类型，用于返回错误码，可根据实际情况进行修改 作用 根据上面第二部分的流程说明中”调整人脸检测框流程“的步骤对GetFaceBox检测出来的人脸框进行调整，使其可以包含所有的人脸特征点 1int ImageStandard(float &amp; rate_w, float &amp; rate_h, cv::Mat frame, std::vector&lt;std::vector&lt;int&gt;&gt; face_box, std::vector&lt;cv::Mat&gt; &amp; img_resize_vector) 参数 rate_w —— 缩放人脸框的x轴方向比例 rate_h —— 缩放人脸框的y轴方向比例 frame —— 待检测人脸框的图像 face_box —— 经过AdjustFaceBox调整过后的人脸检测框 img_resize_vector —— 存储根据上面人脸检测框crop出来的人脸图片 返回值 int类型，用于返回错误码，可根据实际情况进行修改 作用 为了达到更高的精度，ERT检测人脸特征点需要224x224的纯人脸图像，所以要根据上面得到的人脸框将人脸从原图中crop出来，并将其resize到224x224大小。而由于后面需要将这些点重新映射到原图上，所以需要rate_w和rate_h来保存缩放比例 1int detectFaceLandmark(float &amp; rate_w, float &amp; rate_h, std::vector&lt;int&gt; face_box, cv::Mat image, std::vector&lt;std::vector&lt;int&gt;&gt; &amp; landmark, bool flag, double &amp; time) 参数 rate_w —— 缩放人脸框的x轴方向比例 rate_h —— 缩放人脸框的y轴方向比例 face_box —— 经过AdjustFaceBox调整过后的人脸检测框 image —— 根据人脸检测框crop出来的人脸图片 landmark —— 检测出来的特征点，是一个68x2的二维vector flag —— 是否需要使用滤波处理 time —— 检测特征点所需时间 返回值 int类型，用于返回错误码，可根据实际情况进行修改 作用 检测根据人脸检测框crop出来的人脸图片中对应的人脸特征点，并将其坐标映射回原图中。如果flag为True，则将该预测出来的特征点进行滤波平滑处理。 1void GetNewPoints(float rate_w, float rate_h, std::vector&lt;int&gt; face_box, std::vector&lt;std::vector&lt;int&gt;&gt; &amp; landmark_pre, std::vector&lt;std::vector&lt;int&gt;&gt; &amp; landmark_pre_ori) 参数 rate_w —— 缩放人脸框的x轴方向比例 rate_h —— 缩放人脸框的y轴方向比例 face_box —— 经过AdjustFaceBox调整过后的人脸检测框 landmark_pre —— 利用ERT检测crop之后的人脸所得到的特征点 landmark_pre_ori —— 将landmark_pre映射到原始输入图像中得到的特征点 返回值 空 作用 实现detectFaceLandmark函数中将ERT检测crop之后的人脸所得到的特征点映射到原始输入图像的功能 1std::vector&lt;std::vector&lt;int&gt;&gt; KalmanFilter(cv::Mat landmark_pre, float height) 参数 landmark_pre —— 对于detectFaceLandmark中ERT方法得到的原始图像中的特征点坐标值，将其转换为cv::Mat形式，并将其进行转置为一个68x2的矩阵 height —— 检测出来的人脸框的高 返回值 landmark_pre经过卡尔曼滤波处理后得到的新的特征点坐标值 作用 根据上面第二部分的流程说明中”卡尔曼滤波处理流程“对ERT检测到的特征点进行平滑处理 1void drawLandmarks(cv::Mat &amp;image, std::vector&lt;std::vector&lt;int&gt;&gt; landmark, cv::Scalar color = cv::Scalar(255, 0, 0), int radius = 3) 参数 image —— 输入的原始待检测图片 landmark —— 特征点坐标值 color —— 在输入图片上画特征点的颜色 radius —— 在输入图片上画特征点的半径值 返回值 空 作用 将检测到的特征点画到输入图片上 1void TestVedioLandmark(FacenetCaffe fc_box, const string root) 参数 fc_box —— FacenetCaffe类的对象 root —— 存放示例视频及其对应标签的根目录 返回值 空 作用 检测示例视频中的人脸位置以及人脸特征点，主函数可以仿照这个函数来写 5、Quick Start 拷贝整个工程文件 1git clone http://git.code.com/camlinzhang/face_detection_and_alignment.git 修改CMakeList.txt （1）编译动态库 12345678910set(SOURCE_FILES src/face_landmark_detection.cpp include/face_landmark_detection.h src/facenet_caffe.cpp include/facenet_caffe.h include/caffe_register.h)......#add_executable(face_landmark $&#123;SOURCE_FILES&#125;)ADD_LIBRARY(face_landmark SHARED $&#123;SOURCE_FILES&#125;)SET(LIBRARY_OUTPUT_PATH $&#123;PROJECT_SOURCE_DIR&#125;)target_link_libraries(face_landmark $&#123;olibs_point&#125; $&#123;bLIBS&#125; $&#123;oLIBS&#125; $&#123;hLIBS&#125; dlib caffe glog gflags protobuf openblas opencv_core opencv_imgproc opencv_highgui opencv_imgcodecs) （2）编译静态库 1234567891011set(SOURCE_FILES src/face_landmark_detection.cpp include/face_landmark_detection.h src/facenet_caffe.cpp include/facenet_caffe.h include/caffe_register.h)......#add_executable(face_landmark $&#123;SOURCE_FILES&#125;)ADD_LIBRARY(face_landmark $&#123;SOURCE_FILES&#125;)SET(LIBRARY_OUTPUT_PATH $&#123;PROJECT_SOURCE_DIR&#125;)target_link_libraries(face_landmark $&#123;olibs_point&#125; $&#123;bLIBS&#125; $&#123;oLIBS&#125; $&#123;hLIBS&#125; dlib caffe glog gflags protobuf openblas opencv_core opencv_imgproc opencv_highgui opencv_imgcodecs) （3）编译可执行文件，用于测试 12345678910set(SOURCE_FILES src/main.cpp src/face_landmark_detection.cpp include/face_landmark_detection.h src/facenet_caffe.cpp include/facenet_caffe.h include/caffe_register.h)......add_executable(face_landmark $&#123;SOURCE_FILES&#125;)#ADD_LIBRARY(face_landmark SHARED $&#123;SOURCE_FILES&#125;)#SET(LIBRARY_OUTPUT_PATH $&#123;PROJECT_SOURCE_DIR&#125;)target_link_libraries(face_landmark $&#123;olibs_point&#125; $&#123;bLIBS&#125; $&#123;oLIBS&#125; $&#123;hLIBS&#125; dlib caffe glog gflags protobuf openblas opencv_core opencv_imgproc opencv_highgui opencv_imgcodecs) 进入工程文件并编译 12345cd face_detection_and_alignmentmkdir buildcd buildcmake ..make -j8 最后 （1）执行可执行文件进行测试(当修改CMakeList.txt用于编译可执行文件进行测试时) 1./face_landmark （2）在工程的根目录下生成库文件(当修改CMakeList.txt用于生成库文件时)]]></content>
      <categories>
        <category>技术博客</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>人脸检测</tag>
        <tag>人脸对齐</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Caffe转NCNN并移植Android配置记录]]></title>
    <url>%2F2018%2F08%2F21%2Fcaffe_ncnn%2F</url>
    <content type="text"><![CDATA[实验目的：将caffe模型转成ncnn可以实现在移动端运行深度学习模型，主要使用：https://github.com/Tencent/ncnn 实验环境：1、系统环境 Mac OS Mojave系统 编译好的caffe源码（可以参考我之前的博客：https://blog.csdn.net/sinat_28731575/article/details/78958348）2、软件 Android Studio 3.2 Genymotion虚拟机（参考：http://www.open-open.com/lib/view/open1466430392743.html） 实验过程1、实验准备1、将 https://github.com/Tencent/ncnn clone到本地后解压，可以看到下面的组织结构：其中 examples是简单的在安卓上使用NCNN的例子，有一个根据这个例子编译好的Android Studio工程： https://github.com/dangbo/ncnn-mobile tools是后面需要用到的一些工具代码，包含了将各种网络转换到NCNN的代码 2、编译好的caffe源码用于后面转换模型使用 2、编译NCNN（1）参照：https://github.com/Tencent/ncnn/wiki/how-to-build中选择一个需要的环境编译，因为我需要在Android上面使用，所以选择了“Build for Android”：这里首先需要安装NDK来编译Android项目，配置NDK环境有以下两种方式： 使用Android Studio来直接安装：在偏好设置中进行如上图所示的配置，就可以配置NDK编译环境以及相关工具，安装好后NDK存放在上面的sdk目录下的ndk-bundle文件夹中 自己到网站上面下载的方式：下载网址为：http://developer.android.com/ndk/downloads/index.html选择合适的版本下载(因为上面的第一种方法虽然简单，但是默认下载最新的NDK，在编译的时候可能会出现后面我会讲到的一些问题，所以这种方式可以根据实际需要选择合适的版本)解压上面下载的NDK压缩包使用下面的命令配置环境变量： 12345678910vim ~/.bash_profile# 在.bash_profile文件的最后添加上（路径根据自己的进行修改）：export PATH=$PATH:/Users/camlin_z/Data/Project/AndroidStudioProjects/android-ndk-r10e# 或者想把环境变量添加成Android Studio配置的NDK的话：export ANDROID_SDK=&quot;/Users/camlin_z/Library/Android/sdk&quot;export ANDROID_NDK=&quot;/Users/camlin_z/Library/Android/sdk/ndk-bundle&quot;export PATH=&quot;$PATH:$ANDROID_SDK/tools:$ANDROID_SDK/platform-tools:$ANDROID_NDK&quot;source ~/.bash_profile 或者想要替换Android Studio中的NDK环境为自己下的版本的话将上面下载的NDK压缩包重命名为ndk-bundle后放到sdk目录下即可 （2）编译libncnn.a根据上面ncnn的github下的教程有： 12345678$ cd &lt;ncnn-root-dir&gt;$ mkdir -p build-android-armv7$ cd build-android-armv7$ cmake -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK/build/cmake/android.toolchain.cmake \ -DANDROID_ABI=&quot;armeabi-v7a&quot; -DANDROID_ARM_NEON=ON \ -DANDROID_PLATFORM=android-14 ..$ make -j4$ make install 即可“build armv7 library”，之后便会在build-android-armv7/install/lib目录下生成libncnn.a，这样ncnn的编译工作就完成了 3、使用NCNN将caffemodel转换成NCNN中需要的格式参照上面ncnn的github下第二个教程：https://github.com/Tencent/ncnn/wiki/how-to-use-ncnn-with-alexnet首先是下载模型以及权重文件： 123train.prototxtdeploy.prototxtsnapshot_10000.caffemodel 然后使用之前编译好的caffe中build/tools文件夹下的upgrade_net_proto_text和upgrade_net_proto_binary两个文件分别处理模型以及权重文件： 12upgrade_net_proto_text [old prototxt] [new prototxt]upgrade_net_proto_binary [old caffemodel] [new caffemodel] 同时要更改数据层的batchsize大小为1： 123456layer &#123; name: &quot;data&quot; type: &quot;Input&quot; top: &quot;data&quot; input_param &#123; shape: &#123; dim: 1 dim: 3 dim: 227 dim: 227 &#125; &#125;&#125; 经过上面的步骤就准备好了需要转换的模型和权重文件。 接下来进入之前clone的 ncnn工程文件： 1234cd tools/caffemkdir buildcmake ..make -j4 就可以在build文件夹中生成caffe2ncnn.cpp对应的可执行文件caffe2ncnn，最后执行： 1caffe2ncnn deploy.prototxt bvlc_alexnet.caffemodel alexnet.param alexnet.bin 就可以得到最后转化的权重以及模型文件：alexnet.param alexnet.bin 4、编译jni生成了.so库文件进入刚刚ncnn工程下的examples中，这是一个用squeeze net作为例子来生成动态链接库的例子，可以看到examples下面有已经按照3中步骤生成好的squeeze net对应的权重和模型文件， 进入的squeezencnn/jni文件夹中，可以看到如下文件架结构： 其中的cpp和h就是我们需要编写的C++文件和头文件，其中包含以下几个部分： 我们需要的C++功能函数以及对应的头文件 C++和java之间的jni接口函数，用于两者之间的信息互通 然后在终端使用 1ndk-build 命令就可以将上面的文件打包成一个 .so动态链接库供Android调用，可以参考：https://blog.csdn.net/CrazyMo_/article/details/52804896 中的讲解，下面我以squeeze net这个例子简单说明一下安卓调用的过程：首先是Android Studio工程中的结构为： 实际上上图中的工程顺序也就是我们建立我们工程的顺序： 按照上面3中的步骤转换的模型就放在assets目录下 然后我们除了MainActivity.java，就可以定义一个自己需要的函数接口类代码，比如这里的SqueezeNcnn.java，里面的内容为： 12345678910111213141516package com.tencent.squeezencnn;import android.graphics.Bitmap;import android.content.Context;public class SqueezeNcnn&#123; // 我们自己定义的类方法，用于实现我们自己的功能（这里可以看到是java） public native boolean Init(byte[] param, byte[] bin, byte[] words); public native String Detect(Bitmap bitmap); static &#123; System.loadLibrary(&quot;squeezencnn&quot;); &#125;&#125; 然后可以参考：https://blog.csdn.net/createchance/article/details/53783490来自动生成jni文件夹下的squeezenet_v1.1.id.h和squeezencnn_jni.cpp，然后在其中进一步编写我们需要实现的功能函数 接着就是JNI代码了，这个部分实际上包含了实现功能的C/C++代码以及jni接口函数两部分，通过上面的生成，我们得到了squeezenet_v1.1.id.h和squeezencnn_jni.cpp，对应于上面SqueezeNcnn.java中的类方法，squeezencnn_jni.cpp中有对应的JNI接口函数：（函数具体内容大家可以到ncnn工程中查看，这里为了说明方便隐去内容）可以看到jni接口函数是在java类函数的前面加上了 1Java_com_tencent_squeezencnn_SqueezeNcnn_ 部分，将java的native方法转换成C函数声明的规则是这样的：Java_{package_and_classname}_{function_name}(JNI arguments)。包名中的点换成单下划线。需要说明的是生成函数中的两个参数：JNIEnv *：这是一个指向JNI运行环境的指针，后面我们会看到，我们通过这个指针访问JNI函数 jobject：这里指代java中的this对象 而对于一些不是接口的功能函数，我们就可以使用C++或者C来编写，而不需要考虑jni 最后就是将上面的代码编译成libsqueezencnn.so动态库这里我们首先需要编写jni目录下的编译配置文件 Android.mk 和 Application.mk ，类似于C++编译中的CMakeLists.txt： Android. mk ：12345678910111213141516171819202122232425262728293031LOCAL_PATH := $(call my-dir)# change this folder path to yoursNCNN_INSTALL_PATH := /Users/camlin_z/Data/Project/AndroidStudioProjects/ncnn-master/build-android-armv7/installinclude $(CLEAR_VARS)LOCAL_MODULE := ncnn# LOCAL_SRC_FILES := $(NCNN_INSTALL_PATH)/$(TARGET_ARCH_ABI)/libncnn.aLOCAL_SRC_FILES := $(NCNN_INSTALL_PATH)/lib/libncnn.ainclude $(PREBUILT_STATIC_LIBRARY)include $(CLEAR_VARS)LOCAL_MODULE := squeezencnnLOCAL_SRC_FILES := squeezencnn_jni.cppLOCAL_C_INCLUDES := $(NCNN_INSTALL_PATH)/includeLOCAL_STATIC_LIBRARIES := ncnnLOCAL_CFLAGS := -O2 -fvisibility=hidden -fomit-frame-pointer -fstrict-aliasing -ffunction-sections -fdata-sections -ffast-mathLOCAL_CPPFLAGS := -O2 -fvisibility=hidden -fvisibility-inlines-hidden -fomit-frame-pointer -fstrict-aliasing -ffunction-sections -fdata-sections -ffast-mathLOCAL_LDFLAGS += -Wl,--gc-sectionsLOCAL_CFLAGS += -fopenmpLOCAL_CPPFLAGS += -fopenmpLOCAL_LDFLAGS += -fopenmpLOCAL_LDLIBS := -lz -llog -ljnigraphicsinclude $(BUILD_SHARED_LIBRARY) 具体里面的配置方法可以参考：http://www.cnblogs.com/wainiwann/p/3837936.html Application. mk： 12345678910# APP_STL := stlport_staticAPP_STL := gnustl_static# APP_ABI := armeabi armeabi-v7a# 注意此处哟啊对应你之前编译ncnn时的版本，比如我之前用的就是armeabi-v7a# 下面就要指定为armeabi-v7a，不能再有后面的arm64-v8aAPP_ABI := armeabi-v7a #arm64-v8aAPP_PLATFORM := android-14# NDK_TOOLCHAIN_VERSION := 4.9 写好上面的各个配置文件之后就可以在终端进入jni文件夹输入： 1ndk-build 命令进行编译生成 libsqueezencnn. so动态链接库，经过了以上的所有步骤得到最后的动态链接库，Android中的函数就可以直接调用来实现对应的功能了]]></content>
      <categories>
        <category>技术博客</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>Caffe</tag>
        <tag>NCNN</tag>
        <tag>Android</tag>
      </tags>
  </entry>
</search>
