<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Camlin Zhang&#39;s Blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://camlinzhang.com/"/>
  <updated>2019-02-12T09:16:02.534Z</updated>
  <id>http://camlinzhang.com/</id>
  
  <author>
    <name>Camlin Zhang</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Hello World</title>
    <link href="http://camlinzhang.com/2019/02/12/hello-world/"/>
    <id>http://camlinzhang.com/2019/02/12/hello-world/</id>
    <published>2019-02-12T09:16:02.534Z</published>
    <updated>2019-02-12T09:16:02.534Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Caffe转NCNN并移植Android配置记录</title>
    <link href="http://camlinzhang.com/2018/08/21/caffe_ncnn/"/>
    <id>http://camlinzhang.com/2018/08/21/caffe_ncnn/</id>
    <published>2018-08-21T06:53:01.000Z</published>
    <updated>2019-03-24T15:38:31.128Z</updated>
    
    <content type="html"><![CDATA[<h2 id="实验目的："><a href="#实验目的：" class="headerlink" title="实验目的："></a>实验目的：</h2><p>将caffe模型转成ncnn可以实现在移动端运行深度学习模型，主要使用：<br><a href="https://github.com/Tencent/ncnn" target="_blank" rel="noopener">https://github.com/Tencent/ncnn</a></p><h2 id="实验环境："><a href="#实验环境：" class="headerlink" title="实验环境："></a>实验环境：</h2><h3 id="1、系统环境"><a href="#1、系统环境" class="headerlink" title="1、系统环境"></a>1、系统环境</h3><ul><li>Mac OS Mojave系统</li><li>编译好的caffe源码（可以参考我之前的博客：<a href="https://blog.csdn.net/sinat_28731575/article/details/78958348）" target="_blank" rel="noopener">https://blog.csdn.net/sinat_28731575/article/details/78958348）</a><h3 id="2、软件"><a href="#2、软件" class="headerlink" title="2、软件"></a>2、软件</h3></li><li>Android Studio 3.2</li><li>Genymotion虚拟机<br>（参考：<a href="http://www.open-open.com/lib/view/open1466430392743.html）" target="_blank" rel="noopener">http://www.open-open.com/lib/view/open1466430392743.html）</a></li></ul><h2 id="实验过程"><a href="#实验过程" class="headerlink" title="实验过程"></a>实验过程</h2><h3 id="1、实验准备"><a href="#1、实验准备" class="headerlink" title="1、实验准备"></a>1、实验准备</h3><p>1、将 <a href="https://github.com/Tencent/ncnn" target="_blank" rel="noopener">https://github.com/Tencent/ncnn</a> clone到本地后解压，可以看到下面的组织结构：<br><img src="https://img-blog.csdnimg.cn/20181031214109797.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NpbmF0XzI4NzMxNTc1,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>其中</p><ul><li>examples是简单的在安卓上使用NCNN的例子，有一个根据这个例子编译好的Android Studio工程： <a href="https://github.com/dangbo/ncnn-mobile" target="_blank" rel="noopener">https://github.com/dangbo/ncnn-mobile</a></li><li>tools是后面需要用到的一些工具代码，包含了将各种网络转换到NCNN的代码</li></ul><p>2、编译好的caffe源码用于后面转换模型使用</p><h3 id="2、编译NCNN"><a href="#2、编译NCNN" class="headerlink" title="2、编译NCNN"></a>2、编译NCNN</h3><p>（1）参照：<a href="https://github.com/Tencent/ncnn/wiki/how-to-build" target="_blank" rel="noopener">https://github.com/Tencent/ncnn/wiki/how-to-build</a><br>中选择一个需要的环境编译，因为我需要在Android上面使用，所以选择了“Build for Android”：<br>这里首先需要安装NDK来编译Android项目，配置NDK环境有以下两种方式：</p><ul><li><p>使用Android Studio来直接安装：<br><img src="https://img-blog.csdnimg.cn/2018103122011249.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NpbmF0XzI4NzMxNTc1,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>在偏好设置中进行如上图所示的配置，就可以配置NDK编译环境以及相关工具，安装好后NDK存放在上面的sdk目录下的ndk-bundle文件夹中</p></li><li><p>自己到网站上面下载的方式：<br>下载网址为：<a href="http://developer.android.com/ndk/downloads/index.html" target="_blank" rel="noopener">http://developer.android.com/ndk/downloads/index.html</a><br>选择合适的版本下载(因为上面的第一种方法虽然简单，但是默认下载最新的NDK，在编译的时候可能会出现后面我会讲到的一些问题，所以这种方式可以根据实际需要选择合适的版本)<br>解压上面下载的NDK压缩包<br>使用下面的命令配置环境变量：</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.bash_profile</span><br><span class="line"></span><br><span class="line"># 在.bash_profile文件的最后添加上（路径根据自己的进行修改）：</span><br><span class="line">export PATH=$PATH:/Users/camlin_z/Data/Project/AndroidStudioProjects/android-ndk-r10e</span><br><span class="line"># 或者想把环境变量添加成Android Studio配置的NDK的话：</span><br><span class="line">export ANDROID_SDK=&quot;/Users/camlin_z/Library/Android/sdk&quot;</span><br><span class="line">export ANDROID_NDK=&quot;/Users/camlin_z/Library/Android/sdk/ndk-bundle&quot;</span><br><span class="line">export PATH=&quot;$PATH:$ANDROID_SDK/tools:$ANDROID_SDK/platform-tools:$ANDROID_NDK&quot;</span><br><span class="line"></span><br><span class="line">source ~/.bash_profile</span><br></pre></td></tr></table></figure><p>或者想要替换Android Studio中的NDK环境为自己下的版本的话将上面下载的NDK压缩包重命名为ndk-bundle后放到sdk目录下即可</p><p>（2）编译libncnn.a<br>根据上面ncnn的github下的教程有：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ cd &lt;ncnn-root-dir&gt;</span><br><span class="line">$ mkdir -p build-android-armv7</span><br><span class="line">$ cd build-android-armv7</span><br><span class="line">$ cmake -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK/build/cmake/android.toolchain.cmake \</span><br><span class="line">    -DANDROID_ABI=&quot;armeabi-v7a&quot; -DANDROID_ARM_NEON=ON \</span><br><span class="line">    -DANDROID_PLATFORM=android-14 ..</span><br><span class="line">$ make -j4</span><br><span class="line">$ make install</span><br></pre></td></tr></table></figure><p>即可“build armv7 library”，之后便会在build-android-armv7/install/lib目录下生成libncnn.a，这样ncnn的编译工作就完成了</p><h3 id="3、使用NCNN将caffemodel转换成NCNN中需要的格式"><a href="#3、使用NCNN将caffemodel转换成NCNN中需要的格式" class="headerlink" title="3、使用NCNN将caffemodel转换成NCNN中需要的格式"></a>3、使用NCNN将caffemodel转换成NCNN中需要的格式</h3><p>参照上面ncnn的github下第二个教程：<br><a href="https://github.com/Tencent/ncnn/wiki/how-to-use-ncnn-with-alexnet" target="_blank" rel="noopener">https://github.com/Tencent/ncnn/wiki/how-to-use-ncnn-with-alexnet</a><br>首先是下载模型以及权重文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">train.prototxt</span><br><span class="line">deploy.prototxt</span><br><span class="line">snapshot_10000.caffemodel</span><br></pre></td></tr></table></figure><p>然后使用之前编译好的caffe中build/tools文件夹下的upgrade_net_proto_text和upgrade_net_proto_binary两个文件分别处理模型以及权重文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">upgrade_net_proto_text [old prototxt] [new prototxt]</span><br><span class="line">upgrade_net_proto_binary [old caffemodel] [new caffemodel]</span><br></pre></td></tr></table></figure><p>同时要更改数据层的batchsize大小为1：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">layer &#123;</span><br><span class="line">  name: &quot;data&quot;</span><br><span class="line">  type: &quot;Input&quot;</span><br><span class="line">  top: &quot;data&quot;</span><br><span class="line">  input_param &#123; shape: &#123; dim: 1 dim: 3 dim: 227 dim: 227 &#125; &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>经过上面的步骤就准备好了需要转换的模型和权重文件。</p><p>接下来进入之前clone的 <a href="https://github.com/Tencent/ncnn" target="_blank" rel="noopener">ncnn工程文件</a>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd tools/caffe</span><br><span class="line">mkdir build</span><br><span class="line">cmake ..</span><br><span class="line">make -j4</span><br></pre></td></tr></table></figure><p>就可以在build文件夹中生成caffe2ncnn.cpp对应的可执行文件caffe2ncnn，最后执行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">caffe2ncnn deploy.prototxt bvlc_alexnet.caffemodel alexnet.param alexnet.bin</span><br></pre></td></tr></table></figure><p>就可以得到最后转化的权重以及模型文件：alexnet.param alexnet.bin</p><h3 id="4、编译jni生成了-so库文件"><a href="#4、编译jni生成了-so库文件" class="headerlink" title="4、编译jni生成了.so库文件"></a>4、编译jni生成了.so库文件</h3><p>进入刚刚ncnn工程下的examples中，这是一个用squeeze net作为例子来生成动态链接库的例子，可以看到examples下面有已经按照3中步骤生成好的squeeze net对应的权重和模型文件，</p><p>进入的squeezencnn/jni文件夹中，可以看到如下文件架结构：<br><img src="https://img-blog.csdnimg.cn/2018110110422615.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NpbmF0XzI4NzMxNTc1,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p>其中的cpp和h就是我们需要编写的C++文件和头文件，其中包含以下几个部分：</p><ul><li>我们需要的C++功能函数以及对应的头文件</li><li>C++和java之间的jni接口函数，用于两者之间的信息互通</li></ul><p>然后在终端使用</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ndk-build</span><br></pre></td></tr></table></figure><p>命令就可以将上面的文件打包成一个 .so动态链接库供Android调用，可以参考：<br><a href="https://blog.csdn.net/CrazyMo_/article/details/52804896" target="_blank" rel="noopener">https://blog.csdn.net/CrazyMo_/article/details/52804896</a> 中的讲解，下面我以squeeze net这个例子简单说明一下安卓调用的过程：<br>首先是Android Studio工程中的结构为：<br><img src="https://img-blog.csdnimg.cn/20181101111713277.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NpbmF0XzI4NzMxNTc1,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p>实际上上图中的工程顺序也就是我们建立我们工程的顺序：</p><ul><li>按照上面3中的步骤转换的模型就放在assets目录下</li><li>然后我们除了MainActivity.java，就可以定义一个自己需要的函数接口类代码，比如这里的SqueezeNcnn.java，里面的内容为：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">package com.tencent.squeezencnn;</span><br><span class="line"></span><br><span class="line">import android.graphics.Bitmap;</span><br><span class="line">import android.content.Context;</span><br><span class="line"></span><br><span class="line">public class SqueezeNcnn</span><br><span class="line">&#123;</span><br><span class="line">// 我们自己定义的类方法，用于实现我们自己的功能（这里可以看到是java）</span><br><span class="line">    public native boolean Init(byte[] param, byte[] bin, byte[] words);</span><br><span class="line"></span><br><span class="line">    public native String Detect(Bitmap bitmap);</span><br><span class="line"></span><br><span class="line">    static &#123;</span><br><span class="line">        System.loadLibrary(&quot;squeezencnn&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后可以参考：<a href="https://blog.csdn.net/createchance/article/details/53783490" target="_blank" rel="noopener">https://blog.csdn.net/createchance/article/details/53783490</a><br>来自动生成jni文件夹下的squeezenet_v1.1.id.h和squeezencnn_jni.cpp，然后在其中进一步编写我们需要实现的功能函数</p><ul><li>接着就是JNI代码了，这个部分实际上包含了实现功能的C/C++代码以及jni接口函数两部分，通过上面的生成，我们得到了squeezenet_v1.1.id.h和squeezencnn_jni.cpp，对应于上面SqueezeNcnn.java中的类方法，squeezencnn_jni.cpp中有对应的JNI接口函数：<br><img src="https://img-blog.csdnimg.cn/20181101113648484.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NpbmF0XzI4NzMxNTc1,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>（函数具体内容大家可以到ncnn工程中查看，这里为了说明方便隐去内容）<br>可以看到jni接口函数是在java类函数的前面加上了</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Java_com_tencent_squeezencnn_SqueezeNcnn_</span><br></pre></td></tr></table></figure><p>部分，将java的native方法转换成C函数声明的规则是这样的：Java_{package_and_classname}_{function_name}(JNI arguments)。包名中的点换成单下划线。需要说明的是生成函数中的两个参数：<br>JNIEnv *：这是一个指向JNI运行环境的指针，后面我们会看到，我们通过这个指针访问JNI函数<br> jobject：这里指代java中的this对象</p><p>而对于一些不是接口的功能函数，我们就可以使用C++或者C来编写，而不需要考虑jni</p><ul><li>最后就是将上面的代码编译成libsqueezencnn.so动态库<br>这里我们首先需要编写jni目录下的编译配置文件 Android.mk 和 Application.mk ，类似于C++编译中的CMakeLists.txt：</li></ul><p>Android. mk ：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">LOCAL_PATH := $(call my-dir)</span><br><span class="line"></span><br><span class="line"># change this folder path to yours</span><br><span class="line">NCNN_INSTALL_PATH := /Users/camlin_z/Data/Project/AndroidStudioProjects/ncnn-master/build-android-armv7/install</span><br><span class="line"></span><br><span class="line">include $(CLEAR_VARS)</span><br><span class="line">LOCAL_MODULE := ncnn</span><br><span class="line"># LOCAL_SRC_FILES := $(NCNN_INSTALL_PATH)/$(TARGET_ARCH_ABI)/libncnn.a</span><br><span class="line">LOCAL_SRC_FILES := $(NCNN_INSTALL_PATH)/lib/libncnn.a</span><br><span class="line">include $(PREBUILT_STATIC_LIBRARY)</span><br><span class="line"></span><br><span class="line">include $(CLEAR_VARS)</span><br><span class="line"></span><br><span class="line">LOCAL_MODULE := squeezencnn</span><br><span class="line">LOCAL_SRC_FILES := squeezencnn_jni.cpp</span><br><span class="line"></span><br><span class="line">LOCAL_C_INCLUDES := $(NCNN_INSTALL_PATH)/include</span><br><span class="line"></span><br><span class="line">LOCAL_STATIC_LIBRARIES := ncnn</span><br><span class="line"></span><br><span class="line">LOCAL_CFLAGS := -O2 -fvisibility=hidden -fomit-frame-pointer -fstrict-aliasing -ffunction-sections -fdata-sections -ffast-math</span><br><span class="line">LOCAL_CPPFLAGS := -O2 -fvisibility=hidden -fvisibility-inlines-hidden -fomit-frame-pointer -fstrict-aliasing -ffunction-sections -fdata-sections -ffast-math</span><br><span class="line">LOCAL_LDFLAGS += -Wl,--gc-sections</span><br><span class="line"></span><br><span class="line">LOCAL_CFLAGS += -fopenmp</span><br><span class="line">LOCAL_CPPFLAGS += -fopenmp</span><br><span class="line">LOCAL_LDFLAGS += -fopenmp</span><br><span class="line"></span><br><span class="line">LOCAL_LDLIBS := -lz -llog -ljnigraphics</span><br><span class="line"></span><br><span class="line">include $(BUILD_SHARED_LIBRARY)</span><br></pre></td></tr></table></figure></p><p>具体里面的配置方法可以参考：<br><a href="http://www.cnblogs.com/wainiwann/p/3837936.html" target="_blank" rel="noopener">http://www.cnblogs.com/wainiwann/p/3837936.html</a></p><p>Application. mk：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># APP_STL := stlport_static</span><br><span class="line">APP_STL := gnustl_static</span><br><span class="line"># APP_ABI := armeabi armeabi-v7a</span><br><span class="line"></span><br><span class="line"># 注意此处哟啊对应你之前编译ncnn时的版本，比如我之前用的就是armeabi-v7a</span><br><span class="line"># 下面就要指定为armeabi-v7a，不能再有后面的arm64-v8a</span><br><span class="line">APP_ABI := armeabi-v7a #arm64-v8a</span><br><span class="line"></span><br><span class="line">APP_PLATFORM := android-14</span><br><span class="line"># NDK_TOOLCHAIN_VERSION := 4.9</span><br></pre></td></tr></table></figure><p>写好上面的各个配置文件之后就可以在终端进入jni文件夹输入：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ndk-build</span><br></pre></td></tr></table></figure><p>命令进行编译生成 libsqueezencnn. so动态链接库，经过了以上的所有步骤得到最后的动态链接库，Android中的函数就可以直接调用来实现对应的功能了</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;实验目的：&quot;&gt;&lt;a href=&quot;#实验目的：&quot; class=&quot;headerlink&quot; title=&quot;实验目的：&quot;&gt;&lt;/a&gt;实验目的：&lt;/h2&gt;&lt;p&gt;将caffe模型转成ncnn可以实现在移动端运行深度学习模型，主要使用：&lt;br&gt;&lt;a href=&quot;https://g
      
    
    </summary>
    
      <category term="技术博客" scheme="http://camlinzhang.com/categories/%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2/"/>
    
      <category term="深度学习" scheme="http://camlinzhang.com/categories/%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Caffe" scheme="http://camlinzhang.com/tags/Caffe/"/>
    
      <category term="NCNN" scheme="http://camlinzhang.com/tags/NCNN/"/>
    
      <category term="Android" scheme="http://camlinzhang.com/tags/Android/"/>
    
  </entry>
  
  <entry>
    <title>人脸检测和人脸对齐C++工程</title>
    <link href="http://camlinzhang.com/2018/08/21/face_detector/"/>
    <id>http://camlinzhang.com/2018/08/21/face_detector/</id>
    <published>2018-08-21T06:53:01.000Z</published>
    <updated>2019-03-24T15:28:08.967Z</updated>
    
    <content type="html"><![CDATA[<h1 id="人脸检测和人脸对齐C-工程"><a href="#人脸检测和人脸对齐C-工程" class="headerlink" title="人脸检测和人脸对齐C++工程"></a>人脸检测和人脸对齐C++工程</h1><h2 id="1、前言"><a href="#1、前言" class="headerlink" title="1、前言"></a>1、前言</h2><p>该工程分为人脸检测，人脸对齐和特征点平滑处理三个部分。</p><p><strong>人脸检测</strong></p><p>采用FaceBoxes作为解决方案，参考论文《FaceBoxes: A CPU Real-time Face Detector with High Accuracy》。并且在该论文提出的网络结构基础上，进行了网络压缩，使其达到更快的速度，详情见model文件夹中的README.md</p><p><strong>人脸对齐</strong></p><p>采用dlib库中的ERT作为解决方案，参考论文《One Millisecond Face Alignment with an Ensemble of Regression Trees》</p><p><strong>特征点平滑处理</strong></p><p>由于使用ERT进行视频帧的特征点检测时，特征点会出现明显的抖动，所以采用卡尔曼滤波进行平滑处理，参考论文《Automatic facial landmark tracking in video sequences using kalman filter assisted active shape models》</p><h2 id="2、流程说明"><a href="#2、流程说明" class="headerlink" title="2、流程说明"></a>2、流程说明</h2><p><strong>总体流程</strong></p><p><img src="/2018/08/21/face_detector/flow_diagram.jpg" alt="flow_diagram"></p><p><strong>调整人脸检测框流程</strong></p><p>在上述流程中，由于检测算法得到的人脸框普遍无法将所有的68个人脸特征点包含进来，因此引入调整人脸检测框位置这一步，具体步骤如下图所示：</p><p><img src="/2018/08/21/face_detector/adjust_flow_diagram.jpg" alt="adjust_flow_diagram"></p><p><strong>卡尔曼滤波处理流程</strong></p><p>卡尔曼滤波分别针对68个特征点中嘴部、眼睛、面部轮廓和其他区域4个部分进行滤波，这四个部分的原理相同，只是参数的设置不同。以其中一个为例，如下图所示：</p><p><img src="/2018/08/21/face_detector/kalman_filter_flow_diagram.jpg" alt="kalman_filter_flow_diagram"></p><h2 id="3、依赖环境"><a href="#3、依赖环境" class="headerlink" title="3、依赖环境"></a>3、依赖环境</h2><ul><li>FaceBoxes caffe环境</li><li>dlib 19.15</li><li>Opencv 3.1.0</li><li>CentOS Linux release 7.2</li></ul><h2 id="4、API"><a href="#4、API" class="headerlink" title="4、API"></a>4、API</h2><p><strong>类说明</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">FacenetCaffe</span><br></pre></td></tr></table></figure><ul><li>该类用于封装人脸检测的功能函数</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">FaceLandmarkDetector</span><br></pre></td></tr></table></figure><ul><li>该类用于封装人脸特征点检测的功能函数</li></ul><p><strong>函数说明</strong></p><p><strong>class FacenetCaffe</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int initModel(const string &amp; model_path, const string &amp; weights_path, const string &amp; mean_value)</span><br></pre></td></tr></table></figure><p>参数</p><ul><li>model_path —— 网络模型路径</li><li>weights_path —— 网络权重路径</li><li>mean_value —— 图像均值</li></ul><p>返回值</p><ul><li>int类型，用于返回错误码，可根据实际情况进行修改</li></ul><p>作用</p><ul><li>初始化人脸检测模型</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vector&lt;vector&lt;float&gt;&gt; detectFace(const cv::Mat &amp; img)</span><br></pre></td></tr></table></figure><p>参数</p><ul><li>img —— 待检测图片</li></ul><p>返回值</p><ul><li>检测到人脸的坐标值</li></ul><p>作用</p><ul><li>检测img中人脸坐标值</li></ul><p><strong>class FaceLandmarkDetector</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">void init(const string model_path)</span><br></pre></td></tr></table></figure><p>参数</p><ul><li>model_path —— ERT模型路径</li></ul><p>返回值</p><ul><li>空</li></ul><p>作用</p><ul><li>初始化ERT模型和卡尔曼滤波参数</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int GetFaceBox(FacenetCaffe fc_box, cv::Mat image, std::vector&lt;std::vector&lt;int&gt;&gt; &amp; face_box, float confidence_threshold, double &amp; time_detec)</span><br></pre></td></tr></table></figure><p>参数</p><ul><li>fc_box —— FacenetCaffe类的对象</li><li>image —— 待检测人脸框的图像</li><li>face_box —— 检测出来的人脸框</li><li>confidence_threshold —— 置信度阈值</li><li>time_detec —— 检测时间</li></ul><p>返回值</p><ul><li>int类型，用于返回错误码，可根据实际情况进行修改</li></ul><p>作用</p><ul><li>利用类FacenetCaffe中的detectFace方法检测图片的人脸框位置，并计算检测时间</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int AdjustFaceBox(cv::Mat image, std::vector&lt;std::vector&lt;int&gt;&gt; &amp; face_box)</span><br></pre></td></tr></table></figure><p>参数</p><ul><li>image —— 待检测人脸框的图像</li><li>face_box —— 由GetFaceBox检测出来的人脸框</li></ul><p>返回值</p><ul><li>int类型，用于返回错误码，可根据实际情况进行修改</li></ul><p>作用</p><ul><li>根据上面第二部分的流程说明中”调整人脸检测框流程“的步骤对GetFaceBox检测出来的人脸框进行调整，使其可以包含所有的人脸特征点</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int ImageStandard(float &amp; rate_w, float &amp; rate_h, cv::Mat frame, std::vector&lt;std::vector&lt;int&gt;&gt; face_box, std::vector&lt;cv::Mat&gt; &amp; img_resize_vector)</span><br></pre></td></tr></table></figure><p>参数</p><ul><li>rate_w —— 缩放人脸框的x轴方向比例</li><li>rate_h —— 缩放人脸框的y轴方向比例</li><li>frame —— 待检测人脸框的图像</li><li>face_box —— 经过AdjustFaceBox调整过后的人脸检测框</li><li>img_resize_vector —— 存储根据上面人脸检测框crop出来的人脸图片</li></ul><p>返回值</p><ul><li>int类型，用于返回错误码，可根据实际情况进行修改</li></ul><p>作用</p><ul><li>为了达到更高的精度，ERT检测人脸特征点需要224x224的纯人脸图像，所以要根据上面得到的人脸框将人脸从原图中crop出来，并将其resize到224x224大小。而由于后面需要将这些点重新映射到原图上，所以需要rate_w和rate_h来保存缩放比例</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int detectFaceLandmark(float &amp; rate_w, float &amp; rate_h, std::vector&lt;int&gt; face_box, cv::Mat image, std::vector&lt;std::vector&lt;int&gt;&gt; &amp; landmark, bool flag, double &amp; time)</span><br></pre></td></tr></table></figure><p>参数</p><ul><li>rate_w —— 缩放人脸框的x轴方向比例</li><li>rate_h —— 缩放人脸框的y轴方向比例</li><li>face_box —— 经过AdjustFaceBox调整过后的人脸检测框</li><li>image —— 根据人脸检测框crop出来的人脸图片</li><li>landmark —— 检测出来的特征点，是一个68x2的二维vector</li><li>flag —— 是否需要使用滤波处理</li><li>time —— 检测特征点所需时间</li></ul><p>返回值</p><ul><li>int类型，用于返回错误码，可根据实际情况进行修改</li></ul><p>作用</p><ul><li>检测根据人脸检测框crop出来的人脸图片中对应的人脸特征点，并将其坐标映射回原图中。如果flag为True，则将该预测出来的特征点进行滤波平滑处理。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">void GetNewPoints(float rate_w, float rate_h, std::vector&lt;int&gt; face_box, std::vector&lt;std::vector&lt;int&gt;&gt; &amp; landmark_pre, std::vector&lt;std::vector&lt;int&gt;&gt; &amp; landmark_pre_ori)</span><br></pre></td></tr></table></figure><p>参数</p><ul><li>rate_w —— 缩放人脸框的x轴方向比例</li><li>rate_h —— 缩放人脸框的y轴方向比例</li><li>face_box —— 经过AdjustFaceBox调整过后的人脸检测框</li><li>landmark_pre —— 利用ERT检测crop之后的人脸所得到的特征点</li><li>landmark_pre_ori —— 将landmark_pre映射到原始输入图像中得到的特征点</li></ul><p>返回值</p><ul><li>空</li></ul><p>作用</p><ul><li>实现detectFaceLandmark函数中将ERT检测crop之后的人脸所得到的特征点映射到原始输入图像的功能</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">std::vector&lt;std::vector&lt;int&gt;&gt; KalmanFilter(cv::Mat landmark_pre, float height)</span><br></pre></td></tr></table></figure><p>参数</p><ul><li>landmark_pre —— 对于detectFaceLandmark中ERT方法得到的原始图像中的特征点坐标值，将其转换为cv::Mat形式，并将其进行转置为一个68x2的矩阵</li><li>height —— 检测出来的人脸框的高</li></ul><p>返回值</p><ul><li>landmark_pre经过卡尔曼滤波处理后得到的新的特征点坐标值</li></ul><p>作用</p><ul><li>根据上面第二部分的流程说明中”卡尔曼滤波处理流程“对ERT检测到的特征点进行平滑处理</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">void drawLandmarks(cv::Mat &amp;image, std::vector&lt;std::vector&lt;int&gt;&gt; landmark, cv::Scalar color = cv::Scalar(255, 0, 0), int radius = 3)</span><br></pre></td></tr></table></figure><p>参数</p><ul><li>image —— 输入的原始待检测图片</li><li>landmark —— 特征点坐标值</li><li>color —— 在输入图片上画特征点的颜色</li><li>radius —— 在输入图片上画特征点的半径值</li></ul><p>返回值</p><ul><li>空</li></ul><p>作用</p><ul><li>将检测到的特征点画到输入图片上</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">void TestVedioLandmark(FacenetCaffe fc_box, const string root)</span><br></pre></td></tr></table></figure><p>参数</p><ul><li>fc_box —— FacenetCaffe类的对象</li><li>root —— 存放示例视频及其对应标签的根目录</li></ul><p>返回值</p><ul><li>空</li></ul><p>作用</p><ul><li>检测示例视频中的人脸位置以及人脸特征点，主函数可以仿照这个函数来写</li></ul><h2 id="5、Quick-Start"><a href="#5、Quick-Start" class="headerlink" title="5、Quick Start"></a>5、Quick Start</h2><ul><li>拷贝整个工程文件</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone http://git.code.com/camlinzhang/face_detection_and_alignment.git</span><br></pre></td></tr></table></figure><ul><li>修改CMakeList.txt</li></ul><p>（1）编译动态库</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">set(SOURCE_FILES src/face_landmark_detection.cpp include/face_landmark_detection.h src/facenet_caffe.cpp include/facenet_caffe.h include/caffe_register.h)</span><br><span class="line"></span><br><span class="line">......</span><br><span class="line"></span><br><span class="line">#add_executable(face_landmark $&#123;SOURCE_FILES&#125;)</span><br><span class="line"></span><br><span class="line">ADD_LIBRARY(face_landmark SHARED $&#123;SOURCE_FILES&#125;)</span><br><span class="line">SET(LIBRARY_OUTPUT_PATH $&#123;PROJECT_SOURCE_DIR&#125;)</span><br><span class="line"></span><br><span class="line">target_link_libraries(face_landmark $&#123;olibs_point&#125; $&#123;bLIBS&#125; $&#123;oLIBS&#125; $&#123;hLIBS&#125; dlib caffe glog gflags protobuf openblas opencv_core opencv_imgproc opencv_highgui opencv_imgcodecs)</span><br></pre></td></tr></table></figure><p>（2）编译静态库</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">set(SOURCE_FILES src/face_landmark_detection.cpp include/face_landmark_detection.h src/facenet_caffe.cpp include/facenet_caffe.h include/caffe_register.h)</span><br><span class="line"></span><br><span class="line">......</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#add_executable(face_landmark $&#123;SOURCE_FILES&#125;)</span><br><span class="line"></span><br><span class="line">ADD_LIBRARY(face_landmark $&#123;SOURCE_FILES&#125;)</span><br><span class="line">SET(LIBRARY_OUTPUT_PATH $&#123;PROJECT_SOURCE_DIR&#125;)</span><br><span class="line"></span><br><span class="line">target_link_libraries(face_landmark $&#123;olibs_point&#125; $&#123;bLIBS&#125; $&#123;oLIBS&#125; $&#123;hLIBS&#125; dlib caffe glog gflags protobuf openblas opencv_core opencv_imgproc opencv_highgui opencv_imgcodecs)</span><br></pre></td></tr></table></figure><p>（3）编译可执行文件，用于测试</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">set(SOURCE_FILES src/main.cpp src/face_landmark_detection.cpp include/face_landmark_detection.h src/facenet_caffe.cpp include/facenet_caffe.h include/caffe_register.h)</span><br><span class="line"></span><br><span class="line">......</span><br><span class="line"></span><br><span class="line">add_executable(face_landmark $&#123;SOURCE_FILES&#125;)</span><br><span class="line"></span><br><span class="line">#ADD_LIBRARY(face_landmark SHARED $&#123;SOURCE_FILES&#125;)</span><br><span class="line">#SET(LIBRARY_OUTPUT_PATH $&#123;PROJECT_SOURCE_DIR&#125;)</span><br><span class="line"></span><br><span class="line">target_link_libraries(face_landmark $&#123;olibs_point&#125; $&#123;bLIBS&#125; $&#123;oLIBS&#125; $&#123;hLIBS&#125; dlib caffe glog gflags protobuf openblas opencv_core opencv_imgproc opencv_highgui opencv_imgcodecs)</span><br></pre></td></tr></table></figure><ul><li>进入工程文件并编译</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd face_detection_and_alignment</span><br><span class="line">mkdir build</span><br><span class="line">cd build</span><br><span class="line">cmake ..</span><br><span class="line">make -j8</span><br></pre></td></tr></table></figure><ul><li>最后</li></ul><p>（1）执行可执行文件进行测试(当修改CMakeList.txt用于编译可执行文件进行测试时)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./face_landmark</span><br></pre></td></tr></table></figure><p>（2）在工程的根目录下生成库文件(当修改CMakeList.txt用于生成库文件时)</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;人脸检测和人脸对齐C-工程&quot;&gt;&lt;a href=&quot;#人脸检测和人脸对齐C-工程&quot; class=&quot;headerlink&quot; title=&quot;人脸检测和人脸对齐C++工程&quot;&gt;&lt;/a&gt;人脸检测和人脸对齐C++工程&lt;/h1&gt;&lt;h2 id=&quot;1、前言&quot;&gt;&lt;a href=&quot;#1、前
      
    
    </summary>
    
      <category term="技术博客" scheme="http://camlinzhang.com/categories/%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2/"/>
    
      <category term="深度学习" scheme="http://camlinzhang.com/categories/%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="人脸检测" scheme="http://camlinzhang.com/tags/%E4%BA%BA%E8%84%B8%E6%A3%80%E6%B5%8B/"/>
    
      <category term="人脸对齐" scheme="http://camlinzhang.com/tags/%E4%BA%BA%E8%84%B8%E5%AF%B9%E9%BD%90/"/>
    
      <category term="深度学习" scheme="http://camlinzhang.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
</feed>
